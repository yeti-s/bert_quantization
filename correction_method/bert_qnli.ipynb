{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datetime\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/yeti/.cache/huggingface/datasets/glue/qnli/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe047dc566c94fb5874fc10cbed0c3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\yeti\\.cache\\huggingface\\datasets\\glue\\qnli\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-0a058f181b8eb5a6.arrow\n",
      "Loading cached processed dataset at C:\\Users\\yeti\\.cache\\huggingface\\datasets\\glue\\qnli\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-99316a52d64a9c1a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\yeti\\.cache\\huggingface\\datasets\\glue\\qnli\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-1ffa07c8055df33c.arrow\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 256\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 2e-5\n",
    "EPS = 1e-8\n",
    "WARMUP = 100\n",
    "\n",
    "# hh:mm:ss\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))    \n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "dataset = load_dataset('glue', 'qnli')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def tokenize(data):\n",
    "    return tokenizer(data['question'], data['sentence'], truncation=True, max_length=MAX_LENGTH, padding='max_length')\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True, batch_size=5000)\n",
    "\n",
    "def create_dataloader(dataset, batch_size):\n",
    "    input_ids = torch.tensor(dataset['input_ids'])\n",
    "    attention_masks = torch.tensor(dataset['attention_mask'])\n",
    "    labels = torch.tensor(dataset['label'])\n",
    "    tensor_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    random_sampler = RandomSampler(tensor_dataset)\n",
    "    return DataLoader(tensor_dataset, sampler=random_sampler, batch_size = batch_size)\n",
    "\n",
    "train_dataloader = create_dataloader(tokenized_dataset['train'], BATCH_SIZE)\n",
    "test_dataloader = create_dataloader(tokenized_dataset['validation'], BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device):\n",
    "    optimizer = AdamW(model.parameters(), lr = LEARNING_RATE, eps = EPS)\n",
    "    total_steps = len(train_dataloader) * EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP, num_training_steps=total_steps)\n",
    "\n",
    "    model.to(device)\n",
    "    start_time = time.time()\n",
    "\n",
    "    def checkpoint():\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'total_loss': total_loss\n",
    "        }, 'cola_checkpoint.pt')\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        print(f'--- training {epoch + 1} / {EPOCHS}')\n",
    "        \n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            if (step+1) % 500 == 0:\n",
    "                checkpoint()\n",
    "                print(f'--------- {(step+1) * BATCH_SIZE} / {len(train_dataloader) * BATCH_SIZE} trained.', format_time(time.time() - start_time))\n",
    "\n",
    "            batch_inputs = tuple(t.to(device) for t in batch)\n",
    "            inputs = {\n",
    "                'input_ids': batch_inputs[0],\n",
    "                'attention_mask': batch_inputs[1],\n",
    "                'labels': batch_inputs[2]\n",
    "            }\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            \n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        print(f'Epoch {epoch + 1} - Average training loss: {avg_train_loss}')\n",
    "        checkpoint()\n",
    "    print(f'--- train finished. {format_time(time.time() - start_time)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, device):\n",
    "    model.to(device)\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    start_time = time.time()\n",
    "    num_items = 0\n",
    "\n",
    "    labels = np.array([])\n",
    "    predictions = np.array([])\n",
    "\n",
    "\n",
    "    print('--- evaluating')\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        if (step+1) % 100 == 0:\n",
    "            print(f'------ {(step+1)*BATCH_SIZE} / {len(test_dataloader) * BATCH_SIZE}', format_time(time.time() - start_time))\n",
    "\n",
    "        batch_inputs = tuple(t.to(device) for t in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch_inputs[0],\n",
    "            'attention_mask': batch_inputs[1],\n",
    "            'labels': batch_inputs[2]\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "        \n",
    "        total_eval_loss += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        labels = np.concatenate((batch_inputs[2].to('cpu').numpy(), labels))\n",
    "        predictions = np.concatenate((logits.argmax(axis=1), predictions))\n",
    "\n",
    "        num_items += BATCH_SIZE\n",
    "        \n",
    "    avg_eval_loss = total_eval_loss / len(test_dataloader)\n",
    "    avg_eval_accuracy = total_eval_accuracy / num_items\n",
    "    print(f'--- evaluating f1: {f1_score(labels, predictions)}, evaluating loss: {avg_eval_loss:.4f} {format_time(time.time() - start_time)}')\n",
    "    print(f'num total : {predictions.shape[0]},  num rights : {np.sum(predictions == labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train()\n",
    "# train_model(model, torch.device('cuda'))\n",
    "# torch.save(model, \"qnli_trained100.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original BERT model score\n",
      "--- evaluating\n",
      "------ 800 / 5464 0:03:26\n",
      "------ 1600 / 5464 0:06:53\n",
      "------ 2400 / 5464 0:10:20\n",
      "------ 3200 / 5464 0:13:40\n",
      "------ 4000 / 5464 0:17:00\n",
      "------ 4800 / 5464 0:20:20\n",
      "--- evaluating f1: 0.9003075809661661, evaluating loss: 0.6187 0:23:07\n",
      "num total : 5463,  num rights : 4912\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../task/qnli_checkpoint.pt')['model_state_dict'])\n",
    "model.eval()\n",
    "print(\"original BERT model score\")\n",
    "evaluate_model(model, torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantized BERT model score\n",
      "--- evaluating\n",
      "------ 800 / 5464 0:02:49\n",
      "------ 1600 / 5464 0:05:39\n",
      "------ 2400 / 5464 0:08:29\n",
      "------ 3200 / 5464 0:11:20\n",
      "------ 4000 / 5464 0:14:11\n",
      "------ 4800 / 5464 0:17:02\n",
      "--- evaluating f1: 0.8946991404011461, evaluating loss: 0.5456 0:19:25\n",
      "num total : 5463,  num rights : 4875\n",
      "quantized encoder BERT model score\n",
      "--- evaluating\n",
      "------ 800 / 5464 0:02:49\n",
      "------ 1600 / 5464 0:05:40\n",
      "------ 2400 / 5464 0:08:31\n",
      "------ 3200 / 5464 0:11:22\n",
      "------ 4000 / 5464 0:14:12\n",
      "------ 4800 / 5464 0:17:02\n",
      "--- evaluating f1: 0.8925116445718381, evaluating loss: 0.5411 0:19:25\n",
      "num total : 5463,  num rights : 4863\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "qe_model = copy.deepcopy(model)\n",
    "qe_model.eval()\n",
    "qe_model.to('cpu')\n",
    "q_model = torch.quantization.quantize_dynamic(qe_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "qe_model.bert.encoder = q_model.bert.encoder\n",
    "\n",
    "print(\"quantized BERT model score\")\n",
    "evaluate_model(q_model, torch.device('cpu'))\n",
    "\n",
    "print(\"quantized encoder BERT model score\")\n",
    "evaluate_model(qe_model, torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 16 out 16 stride 1\n",
      "in 16 out 24 stride 2\n",
      "in 24 out 24 stride 1\n",
      "in 24 out 24 stride 1\n",
      "in 24 out 24 stride 1\n",
      "in 24 out 24 stride 1\n",
      "in 24 out 40 stride 2\n",
      "in 40 out 40 stride 1\n",
      "in 40 out 40 stride 1\n",
      "in 40 out 40 stride 1\n",
      "in 40 out 40 stride 1\n",
      "in 40 out 40 stride 1\n",
      "in 40 out 80 stride 2\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 112 stride 1\n",
      "in 112 out 112 stride 1\n",
      "in 112 out 112 stride 1\n",
      "in 112 out 112 stride 1\n",
      "in 112 out 112 stride 1\n",
      "in 112 out 112 stride 1\n",
      "in 112 out 160 stride 2\n",
      "in 160 out 160 stride 1\n",
      "in 160 out 160 stride 1\n",
      "in 160 out 160 stride 1\n",
      "in 160 out 160 stride 1\n",
      "in 160 out 320 stride 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeti\\anaconda3\\envs\\py309\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- training 1 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeti\\anaconda3\\envs\\py309\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([256, 768])) that is different to the input size (torch.Size([8, 256, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.3096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(18.7917, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6687, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(2.8995, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(11.4486, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(13.9203, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(2.0341, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(1.2068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7365, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(4.5660, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(2.7615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(2.1383, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0705, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6995, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7410, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7320, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9362, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.8501, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6253, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.9500, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5915, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3412, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2580, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2150, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2227, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2416, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2468, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2495, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2620, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2163, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2783, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2261, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2266, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1948, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2436, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2216, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1932, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1689, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1990, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1866, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1807, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1661, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1993, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1756, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1767, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1687, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1905, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1792, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1501, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1874, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1715, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1515, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1592, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1280, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1655, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1284, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1591, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1451, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1775, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1381, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1309, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1478, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1295, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1910, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1623, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1436, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1342, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1603, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1233, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1633, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1246, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1543, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1469, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1788, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1533, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1359, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1402, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1511, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1152, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1563, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1529, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1582, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1406, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1690, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1739, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1536, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1448, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1252, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1614, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1385, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1505, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1419, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1559, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1415, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1148, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1262, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1167, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1664, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1347, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1359, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1417, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1225, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1630, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1322, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1145, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1093, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1106, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1158, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1363, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1085, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1281, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1098, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1418, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1079, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1160, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1800, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1111, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1629, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1327, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1251, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1121, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1137, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1227, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1070, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1082, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1274, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0957, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1168, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1193, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1123, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1455, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1168, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1240, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1428, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0995, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1304, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1210, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "average training loss : 0.0334758718315064, elapsed : 0:00:23\n",
      "--- training 2 / 2\n",
      "tensor(0.1099, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1125, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1422, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1311, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1063, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1286, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0998, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1177, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1634, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1244, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1537, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1275, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0982, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1130, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1106, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1142, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1547, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1557, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1173, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1115, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0994, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1109, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1175, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1076, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1159, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0952, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1907, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1245, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1595, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3758, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3212, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1923, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1768, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1791, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2331, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2300, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1931, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1656, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1551, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1511, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2516, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1694, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1660, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1471, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1271, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1782, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1290, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1455, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1393, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1481, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1552, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1711, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1164, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1397, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1493, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1221, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1486, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1580, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1277, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1318, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1445, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1828, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1525, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1249, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1545, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1412, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1865, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1363, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1593, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1812, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1419, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1326, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1287, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1249, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1680, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1100, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1441, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1147, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0997, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1158, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1153, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1283, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1164, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1081, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1450, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1249, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1213, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1176, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1174, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1732, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1119, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1258, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1213, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1118, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1098, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1253, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1536, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1245, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1211, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1280, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1186, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1445, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1459, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1114, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1123, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1797, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1757, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1538, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2455, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1190, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1426, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1360, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1176, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1157, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1330, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1605, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1072, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1105, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1842, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1200, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1215, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1240, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1282, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1414, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1307, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1316, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1214, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1315, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1479, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "average training loss : 0.007631460065431784, elapsed : 0:00:20\n",
      "--- train finished. elapsed : 0:00:43\n",
      "correction model size  12.29998779296875\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.relpath(\".\"))\n",
    "from correction_encoder import create_corrected_encoder, train_correction_model, create_train_dataset\n",
    "# from efficientnet_for_encoder import EfficientNetLiteForEncoder\n",
    "from MobileNetV3_for_encoder import MobileNetV3\n",
    "# from resnet50_for_encoder import ResNetForEncoder, BasicBlock\n",
    "\n",
    "\n",
    "# create_train_dataset(model, q_model, train_dataloader, save_path=\"./qnli_encoder_train_dataset\")\n",
    "\n",
    "\n",
    "\n",
    "# correction_model = ResNetForEncoder(BasicBlock, [3,4,6,3], 128, 768)\n",
    "correction_model = MobileNetV3(MAX_LENGTH, 768)\n",
    "correction_model.to('cuda')\n",
    "train_correction_model(correction_model, \"./train_dataset\", save_path=\"./qnli_encoder_mobilenet.pt\", epochs=2)\n",
    "\n",
    "# correction_model.load_state_dict(torch.load('./cola_encoder_mobilenet.pt')['model_state_dict'])\n",
    "# correction_model.load_state_dict(torch.load('./cola_encoder_resnet.pt')['model_state_dict'])\n",
    "\n",
    "total_params = sum(p.numel() for p in correction_model.parameters())\n",
    "total_size = total_params * 4 / (1024 ** 2)  # 모델 사이즈 (MB) 계산\n",
    "print(\"correction model size \", total_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- evaluating\n",
      "------ 800 / 5464 0:04:31\n",
      "------ 1600 / 5464 0:09:04\n",
      "------ 2400 / 5464 0:13:39\n",
      "------ 3200 / 5464 0:18:14\n",
      "------ 4000 / 5464 0:22:49\n",
      "------ 4800 / 5464 0:27:23\n",
      "--- evaluating f1: 0.8917516550366792, evaluating loss: 0.5524 0:31:13\n",
      "num total : 5463,  num rights : 4858\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c_model = create_corrected_encoder(qe_model, correction_model)\n",
    "c_model.to('cpu')\n",
    "c_model.eval()\n",
    "evaluate_model(c_model, torch.device('cpu'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py309",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
