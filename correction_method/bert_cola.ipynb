{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datetime\n",
    "import time\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/yeti/.cache/huggingface/datasets/glue/cola/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c654e44d8cae4b40a4258d133a344815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\yeti\\.cache\\huggingface\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-a11e411136772b5a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\yeti\\.cache\\huggingface\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-2d6bb69b6bcc0406.arrow\n",
      "Loading cached processed dataset at C:\\Users\\yeti\\.cache\\huggingface\\datasets\\glue\\cola\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-199577ef2822b192.arrow\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 2e-5\n",
    "EPS = 1e-8\n",
    "WARMUP = 100\n",
    "\n",
    "# hh:mm:ss\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))    \n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "dataset = load_dataset('glue', 'cola')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize(data):\n",
    "    return tokenizer(data['sentence'], truncation=True, max_length=MAX_LENGTH, padding='max_length')\n",
    "\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize, batched=True, batch_size=5000)\n",
    "\n",
    "def create_dataloader(dataset, batch_size):\n",
    "    input_ids = torch.tensor(dataset['input_ids'])\n",
    "    attention_masks = torch.tensor(dataset['attention_mask'])\n",
    "    labels = torch.tensor(dataset['label'])\n",
    "    tensor_dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    random_sampler = RandomSampler(tensor_dataset)\n",
    "    return DataLoader(tensor_dataset, sampler=random_sampler, batch_size = batch_size)\n",
    "\n",
    "train_dataloader = create_dataloader(tokenized_dataset['train'], BATCH_SIZE)\n",
    "test_dataloader = create_dataloader(tokenized_dataset['validation'], BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, device):\n",
    "    optimizer = AdamW(model.parameters(), lr = LEARNING_RATE, eps = EPS)\n",
    "    total_steps = len(train_dataloader) * EPOCHS\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=WARMUP, num_training_steps=total_steps)\n",
    "\n",
    "    model.to(device)\n",
    "    start_time = time.time()\n",
    "\n",
    "    def checkpoint():\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'total_loss': total_loss\n",
    "        }, 'cola_checkpoint.pt')\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        print(f'--- training {epoch + 1} / {EPOCHS}')\n",
    "        \n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            if (step+1) % 500 == 0:\n",
    "                checkpoint()\n",
    "                print(f'--------- {(step+1) * BATCH_SIZE} / {len(train_dataloader) * BATCH_SIZE} trained.', format_time(time.time() - start_time))\n",
    "\n",
    "            batch_inputs = tuple(t.to(device) for t in batch)\n",
    "            inputs = {\n",
    "                'input_ids': batch_inputs[0],\n",
    "                'attention_mask': batch_inputs[1],\n",
    "                'labels': batch_inputs[2]\n",
    "            }\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            \n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "        print(f'Epoch {epoch + 1} - Average training loss: {avg_train_loss}')\n",
    "        checkpoint()\n",
    "    print(f'--- train finished. {format_time(time.time() - start_time)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, device):\n",
    "    model.to(device)\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    start_time = time.time()\n",
    "    num_items = 0\n",
    "\n",
    "    labels = np.array([])\n",
    "    predictions = np.array([])\n",
    "\n",
    "\n",
    "    print('--- evaluating')\n",
    "    for step, batch in enumerate(test_dataloader):\n",
    "        if (step+1) % 100 == 0:\n",
    "            print(f'------ {(step+1)*BATCH_SIZE} / {len(test_dataloader) * BATCH_SIZE}', format_time(time.time() - start_time))\n",
    "\n",
    "        batch_inputs = tuple(t.to(device) for t in batch)\n",
    "        inputs = {\n",
    "            'input_ids': batch_inputs[0],\n",
    "            'attention_mask': batch_inputs[1],\n",
    "            'labels': batch_inputs[2]\n",
    "        }\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "        \n",
    "        total_eval_loss += loss.item()\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        labels = np.concatenate((batch_inputs[2].to('cpu').numpy(), labels))\n",
    "        predictions = np.concatenate((logits.argmax(axis=1), predictions))\n",
    "\n",
    "        num_items += BATCH_SIZE\n",
    "        \n",
    "    avg_eval_loss = total_eval_loss / len(test_dataloader)\n",
    "    avg_eval_accuracy = total_eval_accuracy / num_items\n",
    "    print(f'--- evaluating f1: {f1_score(labels, predictions)}, evaluating loss: {avg_eval_loss:.4f} {format_time(time.time() - start_time)}')\n",
    "    print(f'num total : {predictions.shape[0]},  num rights : {np.sum(predictions == labels)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train()\n",
    "# train_model(model, torch.device('cuda'))\n",
    "# torch.save(model, \"cola_trained100.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original BERT model score\n",
      "--- evaluating\n",
      "--- evaluating f1: 0.880842659644503, evaluating loss: 0.8401 0:01:41\n",
      "num total : 1043,  num rights : 862\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../task/cola_checkpoint.pt')['model_state_dict'])\n",
    "model.eval()\n",
    "print(\"original BERT model score\")\n",
    "evaluate_model(model, torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantized BERT model score\n",
      "--- evaluating\n",
      "--- evaluating f1: 0.8748370273794002, evaluating loss: 0.4951 0:01:23\n",
      "num total : 1043,  num rights : 851\n",
      "quantized encoder BERT model score\n",
      "--- evaluating\n",
      "--- evaluating f1: 0.8743523316062176, evaluating loss: 0.4872 0:01:23\n",
      "num total : 1043,  num rights : 849\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "qe_model = copy.deepcopy(model)\n",
    "qe_model.eval()\n",
    "qe_model.to('cpu')\n",
    "q_model = torch.quantization.quantize_dynamic(qe_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "qe_model.bert.encoder = q_model.bert.encoder\n",
    "\n",
    "print(\"quantized BERT model score\")\n",
    "evaluate_model(q_model, torch.device('cpu'))\n",
    "\n",
    "print(\"quantized encoder BERT model score\")\n",
    "evaluate_model(qe_model, torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in 16 out 16 stride 1\n",
      "in 16 out 24 stride 2\n",
      "in 24 out 24 stride 1\n",
      "in 24 out 24 stride 1\n",
      "in 24 out 24 stride 1\n",
      "in 24 out 24 stride 1\n",
      "in 24 out 40 stride 2\n",
      "in 40 out 40 stride 1\n",
      "in 40 out 40 stride 1\n",
      "in 40 out 40 stride 1\n",
      "in 40 out 40 stride 1\n",
      "in 40 out 40 stride 1\n",
      "in 40 out 80 stride 2\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 80 stride 1\n",
      "in 80 out 112 stride 1\n",
      "in 112 out 112 stride 1\n",
      "in 112 out 112 stride 1\n",
      "in 112 out 112 stride 1\n",
      "in 112 out 112 stride 1\n",
      "in 112 out 112 stride 1\n",
      "in 112 out 160 stride 2\n",
      "in 160 out 160 stride 1\n",
      "in 160 out 160 stride 1\n",
      "in 160 out 160 stride 1\n",
      "in 160 out 160 stride 1\n",
      "in 160 out 320 stride 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeti\\anaconda3\\envs\\py309\\lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- training 1 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yeti\\anaconda3\\envs\\py309\\lib\\site-packages\\torch\\nn\\modules\\loss.py:536: UserWarning: Using a target size (torch.Size([128, 768])) that is different to the input size (torch.Size([8, 128, 768])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2693, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2698, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.5129, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(1.4823, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(1.0330, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6872, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4282, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.3587, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.6028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.7334, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.4134, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2750, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2467, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2513, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2825, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2355, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1715, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1704, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1806, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1709, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.2469, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1692, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1560, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1246, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1232, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1185, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1454, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1418, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1341, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1303, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1218, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1141, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1234, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1107, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1512, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1121, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1139, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1122, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1173, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0985, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0914, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0927, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0971, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1302, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0986, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0959, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0925, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0880, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0962, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0973, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0982, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0803, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1284, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0966, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0833, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0752, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0938, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0982, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0891, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0934, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0928, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0828, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0925, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0749, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0754, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0894, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0726, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0940, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1079, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0829, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1151, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0829, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0832, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0739, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0717, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0930, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1191, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0888, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0723, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0762, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0862, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0720, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0718, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0688, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0850, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0836, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0713, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0749, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0711, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0786, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0694, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0705, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0690, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0705, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0766, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0650, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0834, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0812, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0686, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0841, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0660, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0714, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0725, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0750, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0679, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0653, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0783, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0695, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0718, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0810, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0683, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0740, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0775, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0682, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0687, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0915, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0675, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0756, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0663, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0753, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0738, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0675, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0688, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0736, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0635, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0696, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0824, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0649, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0652, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0665, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "average training loss : 0.004383355766699157, elapsed : 0:00:16\n",
      "--- training 2 / 2\n",
      "tensor(0.0658, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0774, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0709, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0630, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0644, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0725, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1392, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0628, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0760, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0804, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0623, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0844, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0645, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0647, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0617, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0648, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0717, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0684, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0591, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0771, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0670, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0653, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0983, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0636, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0693, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0767, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0653, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0963, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0808, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0713, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0656, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0745, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0660, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0664, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0633, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0673, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0721, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0629, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0646, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0647, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0935, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0814, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0853, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0692, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0613, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0676, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0671, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0683, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0638, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0677, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0917, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0715, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0723, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0628, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0660, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0627, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0621, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0659, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0707, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0604, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0621, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0837, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0600, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0635, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0652, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0628, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0761, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0604, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0602, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0770, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0663, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0959, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0574, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0574, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0623, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0585, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1001, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0588, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0578, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0696, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0657, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0606, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0871, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0617, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0872, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0644, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0666, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0795, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0602, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0644, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0592, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0764, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0636, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0615, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0584, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0591, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0601, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0562, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0644, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0678, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1140, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1127, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0569, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0683, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0717, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0563, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0720, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0619, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0867, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.1027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0623, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0632, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0677, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0596, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0588, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0585, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0612, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0634, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0603, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0554, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0727, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0738, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0551, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0561, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0616, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0704, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0593, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0709, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0656, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0571, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0625, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0643, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0610, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0576, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0622, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0994, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0588, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "tensor(0.0692, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
      "average training loss : 0.0019169199259896927, elapsed : 0:00:13\n",
      "--- train finished. elapsed : 0:00:28\n",
      "correction model size  11.39324951171875\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.relpath(\".\"))\n",
    "from correction_encoder import create_corrected_encoder, train_correction_model, create_train_dataset\n",
    "# from efficientnet_for_encoder import EfficientNetLiteForEncoder\n",
    "from MobileNetV3_for_encoder import MobileNetV3\n",
    "# from resnet50_for_encoder import ResNetForEncoder, BasicBlock\n",
    "\n",
    "\n",
    "# create_train_dataset(model, q_model, train_dataloader)\n",
    "\n",
    "\n",
    "\n",
    "# correction_model = ResNetForEncoder(BasicBlock, [3,4,6,3], 128, 768)\n",
    "correction_model = MobileNetV3(128, 768)\n",
    "correction_model.to('cuda')\n",
    "train_correction_model(correction_model, \"./train_dataset\", save_path=\"./cola_encoder_mobilenet.pt\", epochs=2)\n",
    "\n",
    "# correction_model.load_state_dict(torch.load('./cola_encoder_mobilenet.pt')['model_state_dict'])\n",
    "# correction_model.load_state_dict(torch.load('./cola_encoder_resnet.pt')['model_state_dict'])\n",
    "\n",
    "total_params = sum(p.numel() for p in correction_model.parameters())\n",
    "total_size = total_params * 4 / (1024 ** 2)  # 모델 사이즈 (MB) 계산\n",
    "print(\"correction model size \", total_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- evaluating\n",
      "--- evaluating f1: 0.87565445026178, evaluating loss: 0.4556 0:02:29\n",
      "num total : 1043,  num rights : 853\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c_model = create_corrected_encoder(qe_model, correction_model)\n",
    "c_model.to('cpu')\n",
    "c_model.eval()\n",
    "evaluate_model(c_model, torch.device('cpu'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py309",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
