{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0e5df2e610>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import sys\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"mnli\" # cola, mnli, qnli, qqp\n",
    "batch_size = 32\n",
    "max_length = 128\n",
    "rt_filename = 'bert-base.plan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "saved_path = f'../ignore/task/bert-base_{task_name}.pt'\n",
    "\n",
    "\n",
    "task = {\n",
    "    \"qnli\":{\n",
    "        \"num_labels\": 2,\n",
    "        \"test_dataset_name\": \"validation\",\n",
    "        \"tokenize\": lambda data:tokenizer(data['question'], data['sentence'], truncation=True, max_length=max_length, padding='max_length')\n",
    "    },\n",
    "    \"mnli\":{\n",
    "        \"num_labels\": 3,\n",
    "        \"test_dataset_name\": \"validation_matched\",\n",
    "        \"tokenize\": lambda data:tokenizer(data['premise'], data['hypothesis'], truncation=True, max_length=max_length, padding='max_length')\n",
    "    },\n",
    "    \"qqp\":{\n",
    "        \"num_labels\": 2,\n",
    "        \"test_dataset_name\": \"validation\",\n",
    "        \"tokenize\": lambda data:tokenizer(data['question1'], data['question2'], truncation=True, max_length=max_length, padding='max_length')\n",
    "    },\n",
    "    \"cola\":{\n",
    "        \"num_labels\": 2,\n",
    "        \"test_dataset_name\": \"validation\",\n",
    "        \"tokenize\": lambda data:tokenizer(data['sentence'], truncation=True, max_length=max_length, padding='max_length')\n",
    "    }\n",
    "}\n",
    "task = task[task_name]\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=task[\"num_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 313M/313M [00:10<00:00, 29.0MB/s] \n",
      "Generating train split: 100%|██████████| 392702/392702 [00:27<00:00, 14258.24 examples/s]\n",
      "Generating validation_matched split: 100%|██████████| 9815/9815 [00:00<00:00, 17068.61 examples/s]\n",
      "Generating validation_mismatched split: 100%|██████████| 9832/9832 [00:00<00:00, 15524.43 examples/s]\n",
      "Generating test_matched split: 100%|██████████| 9796/9796 [00:00<00:00, 16400.62 examples/s]\n",
      "Generating test_mismatched split: 100%|██████████| 9847/9847 [00:00<00:00, 17985.00 examples/s]\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n",
      "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('glue', task_name)\n",
    "tokenize = task['tokenize']\n",
    "tokenized_dataset = tokenize(dataset[task['test_dataset_name']])\n",
    "\n",
    "input_ids = np.array(tokenized_dataset['input_ids'])\n",
    "attention_masks = np.array(tokenized_dataset['attention_mask'])\n",
    "labels = np.array(dataset[task['test_dataset_name']]['label'])\n",
    "\n",
    "max_size = labels.shape[0] - (labels.shape[0] % 32)\n",
    "test_dataset = {'input_ids':input_ids[:max_size,:], 'attention_masks':attention_masks[:max_size,:], 'labels':labels[:max_size], 'size': max_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRT_LOGGER = trt.Logger(trt.Logger.WARNING)\n",
    "EXPLICIT_BATCH = 1 << (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)\n",
    "trt_runtime = trt.Runtime(TRT_LOGGER)\n",
    " \n",
    "with open(rt_filename, 'rb') as f:\n",
    "    engine_data = f.read()\n",
    "engine = trt_runtime.deserialize_cuda_engine(engine_data)\n",
    "\n",
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem, device_mem):\n",
    "        self.host = host_mem\n",
    "        self.device = device_mem\n",
    " \n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    " \n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    " \n",
    "inputs, outputs, bindings, stream = [], [], [], []\n",
    "for binding in engine:\n",
    "    size = trt.volume(engine.get_binding_shape(binding)) * engine.max_batch_size\n",
    "    dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "    \n",
    "    # Allocate host and device buffers\n",
    "    host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "    device_mem = cuda.mem_alloc_like(host_mem)\n",
    "    bindings.append(int(device_mem))\n",
    "    if engine.binding_is_input(binding):\n",
    "        inputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "    else:\n",
    "        outputs.append(HostDeviceMem(host_mem, device_mem))\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_progress(progress):\n",
    "    sys.stdout.write('\\r%d%%' % progress)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def format_time(time):\n",
    "    time_rounded = int(round((time)))\n",
    "    return str(datetime.timedelta(seconds=time_rounded))\n",
    "\n",
    "def eval():\n",
    "    labels = []\n",
    "    predictions = []\n",
    "    index = 0\n",
    "    \n",
    "    stream = cuda.Stream()\n",
    "    num_data = test_dataset['size']\n",
    "    start_time = time.time()\n",
    "    \n",
    "    while(index < num_data):\n",
    "        \n",
    "        input_ids = test_dataset['input_ids'][index:index+batch_size,:]\n",
    "        attention_masks = test_dataset['attention_masks'][index:index+batch_size,:]\n",
    "        label = test_dataset['labels'][index:index+batch_size]\n",
    "        \n",
    "        hosts = [input.host for input in inputs]\n",
    "        input_array = [input_ids, attention_masks]\n",
    "        \n",
    "        for input_array, host in zip(input_array, hosts):\n",
    "            input_array = np.asarray(input_array).astype(trt.nptype(trt.int32)).ravel()\n",
    "            np.copyto(host, input_array)\n",
    "            \n",
    "        [cuda.memcpy_htod_async(input.device, input.host, stream) for input in inputs]\n",
    "        context.execute_async_v2(bindings=bindings, stream_handle=stream.handle)\n",
    "        [cuda.memcpy_dtoh_async(output.host, output.device, stream) for output in outputs]\n",
    "        stream.synchronize()\n",
    "        prediction = [output.host for output in outputs]\n",
    "        \n",
    "        \n",
    "        prediction = np.array(prediction).reshape(batch_size, -1).argmax(1)\n",
    "        predictions.append(prediction)\n",
    "        labels.append(np.array(label))\n",
    "\n",
    "        index += batch_size\n",
    "        update_progress(index / num_data * 100)\n",
    "        \n",
    "    labels = np.concatenate(labels)\n",
    "    predictions = np.concatenate(predictions)\n",
    "        \n",
    "    # print(f' f1: {f1_score(labels, predictions)}, evaluating loss: {avg_eval_loss:.4f}')\n",
    "    print(f' {np.sum(predictions == labels)} / {predictions.shape[0]} ')\n",
    "    print(f' --- evaluation finished {format_time(time.time() - start_time)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% 8155 / 9792 \n",
      " --- evaluation finished 0:00:37\n"
     ]
    }
   ],
   "source": [
    "eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py309",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
